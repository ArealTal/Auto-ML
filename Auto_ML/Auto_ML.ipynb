{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Building your 1st Auto ML Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a “how to” manual for how to create an auto ML application, using an example as a potential template. Auto ML (Automated Machine Learning) is a type of application such that you plug in data and machine learning algorithms are run automatically, outputting a model. Auto ML applications can have a number of possible uses - the fundamental ones are: \n",
    "Data cleaning, choosing the right machine learning algorithm(s), and validation. \n",
    "\n",
    "Though the applications for the auto ml application I created are numerous, the motivation for it is to determine model bias and/or bias in data. When you decide to create an auto ML application, consider what your motivation is. \n",
    "\n",
    "Note: I decided not to include data cleaning as part of this application because there are plenty of applications that already do that. In fact, one possibility is to hook in APIs from other Auto ML applications in order to use other peoples’ work instead of starting from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Start with a  cheatsheet. I used an image that showed which algorithm to use depending on attributes of your dataset. \n",
    "\n",
    "b) Gather some basic information about the dataset that you can easily figure out. This includes:\n",
    "\n",
    "c) You don’t need to figure everything out yourself though. Feel free to ask your user about the dataset to be analyzed. You don’t need to figure out everything on your own. Your user can tell you all types of relevant information, including:\n",
    "\n",
    "d) Create an auditing log. Include the attributes discovered about the dataset, the type of problem being faced (depending on attributes of your data, including:\n",
    "Is the data labeled?\n",
    "If labeled, is the target variable categorical?), which algorithm is used whenever one is used, and what the output of the model is. \n",
    "\n",
    "e) Now is time for training. Choose which algorithm should be run, tune the algorithm, run the algorithm, and output the results.\n",
    "\n",
    "f) The next step after training of any machine learning application is model validation. This is where I decided to focus my efforts. By doing a deeper model evaluation, figuring out which segments of data the model does poorly, you can find issues. Issues could be with the algorithm, with underlying issues related to the dataset, or some other form of bias. \n",
    "\n",
    "g) Prepare for the various types of issues that may have come up. See if you can solve them automatically. For example, if you there is a segment of data that is undersampled (or there are not enough samples), you can oversample the data or create synthetic data from the data that the dataset does not have a sufficient number of samples of). \n",
    "\n",
    "h) Iterage sections e-g\n",
    "\n",
    "\n",
    "i) An important step is to make sure you avoid model drift, the degredation of model performance over time. One type of model drift is due to data drift. In order to avoid data drift, you can create data population reports that compare your data with some baseline dataset to look for changes. Another way to avoid model drift is simply by retraining your models regularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def ask_if_true(question): #, positive_answers = [\"y\", \"yes\", \"true\"]):\n",
    "    var_asking_about = str.lower(input(question+'\\n'))\n",
    "    if var_asking_about in [\"y\", \"yes\", \"true\"]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def create_random_seed():\n",
    "    current_time = int(time.time())\n",
    "    time.sleep(random.randrange(1,5)*0.02) \n",
    "    return current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the observation count more than 50?\n",
    "Is the observation count more than 100,000?\n",
    "Is the observation count more than 10,000?\n",
    "\n",
    "Are you predicting a category, predicting a quantity, or are you exploring?\n",
    "\n",
    "Is it necessary to have only few features that are important?\n",
    "\n",
    "Is any of the data text data?\n",
    "\n",
    "Is the data labeled (is there a target variable with data)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get answers to questions\n",
    "def get_observation_count_comparisons(X):\n",
    "    count_of_observations = len(X)\n",
    "    is_count_of_observations_more_than_50 = (count_of_observations>50)\n",
    "    is_count_of_observations_less_than_100k = (count_of_observations<100000)\n",
    "    is_count_of_observations_less_than_10k = (count_of_observations<10000)\n",
    "    return (is_count_of_observations_more_than_50, \n",
    "            is_count_of_observations_less_than_100k, \n",
    "            is_count_of_observations_less_than_10k)\n",
    "\n",
    "def derive_from_type_of_target_variable(y_type):\n",
    "    is_target_categorical = y_type == \"categorical\"\n",
    "    is_target_quantity = y_type == \"quantity\"\n",
    "    is_exploration = y_type == \"exploring\"\n",
    "    return (is_target_categorical, \n",
    "            is_target_quantity, \n",
    "            is_exploration)\n",
    "\n",
    "def get_is_data_labeled(Y):\n",
    "    is_data_labeled = len(Y) > 0\n",
    "    return is_data_labeled\n",
    "\n",
    "#Collect more data if necessary\n",
    "def get_is_number_categories_known():\n",
    "    if is_target_categorical == True and is_data_labeled == False :\n",
    "        question = \"Do you know how many categories there are? 'yes' or 'no'\\n\"\n",
    "        is_number_categories_known = ask_if_true(question)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithms...\n",
    "\n",
    "classification:\n",
    "'do_LinearSVC', \n",
    "'do_NaiveBayes', \n",
    "'do_KNeighborsClassifier', \n",
    "'do_SVC', \n",
    "'do_SGDClassifier', \n",
    "'do_KernelApproximation'\n",
    "\n",
    "#dimensionality reduction:\n",
    "'do_Randomized_PCA'\n",
    "\n",
    "#Clustering\n",
    "'do_KMeans', \n",
    "'do_gmm', \n",
    "'do_SpectralClustering', \n",
    "'MiniBatchKMeans', \n",
    "'do_MeanShift', \n",
    "'do_VBGMM'\n",
    "\n",
    "#Regression\n",
    "'do_SGDRegressor', \n",
    "'do_Lasso', \n",
    "'do_ElasticNet', \n",
    "'do_Ridge', \n",
    "'do_linear_SVR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating/collecting data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random    \n",
    "\n",
    "def get_data(data_generated=True, filename = ''):\n",
    "    X = []\n",
    "    Y = []\n",
    "    if not data_generated:\n",
    "        #df = pd.read_csv(filename)\n",
    "        df = pd.read_csv('../data/application_data.csv')\n",
    "        \n",
    "        (is_count_of_observations_more_than_50, \n",
    "         is_count_of_observations_less_than_100k, \n",
    "         is_count_of_observations_less_than_10k) = get_observation_count_comparisons(df)\n",
    "        y_type = get_target_variable_type()\n",
    "        is_few_features_important = get_is_few_features_important()\n",
    "        is_any_data_text = get_is_any_data_text()\n",
    "\n",
    "        (is_target_categorical, \n",
    "         is_target_quantity, \n",
    "         is_exploration) = derive_from_type_of_target_variable(y_type)\n",
    "        is_data_labeled = get_is_data_labeled(Y)  \n",
    "        is_number_categories_known = get_is_number_categories_known()\n",
    "    \n",
    "    else:\n",
    "        random = False\n",
    "        if random == True:\n",
    "            is_data_labeled = False\n",
    "            is_number_categories_known = False\n",
    "            np.random.seed(create_random_seed())\n",
    "            number_observations = np.random.choice([0,1, 20, 200, 2000, 10001, 100001])\n",
    "            for _ in range(0,number_observations):\n",
    "                X.append([random.randrange(1,100),\n",
    "                          random.randrange(1,100),\n",
    "                          random.randrange(1,100)])\n",
    "                Y.append(np.random.choice([\"cat\",\"dog\"]))\n",
    "\n",
    "            np.random.seed(create_random_seed())\n",
    "    #         is_count_of_observations_more_than_50 = np.random.choice([True, False])\n",
    "    #         is_count_of_observations_less_than_100k = np.random.choice([True, False])\n",
    "    #         is_count_of_observations_less_than_10k = np.random.choice([True, False])\n",
    "            (is_count_of_observations_more_than_50, \n",
    "             is_count_of_observations_less_than_100k, \n",
    "             is_count_of_observations_less_than_10k) = get_observation_count_comparisons(X)\n",
    "            np.random.seed(create_random_seed())\n",
    "            y_type = np.random.choice([\"categorical\", \"quantity\", \"exploring\"])\n",
    "            np.random.seed(create_random_seed())\n",
    "            is_few_features_important = np.random.choice([True, False])\n",
    "            np.random.seed(create_random_seed())\n",
    "            is_any_data_text = np.random.choice([True, False])\n",
    "            (is_target_categorical, \n",
    "             is_target_quantity, \n",
    "             is_exploration) = derive_from_type_of_target_variable(y_type)\n",
    "            np.random.seed(create_random_seed())\n",
    "            is_data_labeled = np.random.choice([True, False])\n",
    "            np.random.seed(create_random_seed())\n",
    "            is_number_categories_known = np.random.choice([True, False])\n",
    "        else: #generate data for specific things\n",
    "            makeDataForAnAlgorithm = DataFromUser()\n",
    "            (is_data_labeled,\n",
    "                is_number_categories_known,\n",
    "                is_count_of_observations_more_than_50,\n",
    "                is_count_of_observations_less_than_100k,\n",
    "                is_count_of_observations_less_than_10k,\n",
    "                is_few_features_important,\n",
    "                is_any_data_text,\n",
    "                is_target_categorical, \n",
    "                is_target_quantity, \n",
    "                is_exploration) = makeDataForAnAlgorithm.all_user_responses()\n",
    "#debugging\n",
    "#         print(is_count_of_observations_more_than_50)\n",
    "#         print(is_count_of_observations_less_than_100k )\n",
    "#         print(is_count_of_observations_less_than_10k )\n",
    "#         print(y_type )\n",
    "#         print(is_few_features_important )\n",
    "#         print(is_any_data_text )\n",
    "#         print(is_target_categorical )\n",
    "#         print(is_target_quantity)\n",
    "#         print(is_exploration )\n",
    "#         print(is_data_labeled )\n",
    "#         print(is_number_categories_known )\n",
    "#         print(number_observations )\n",
    "            \n",
    "\n",
    "        return (is_count_of_observations_more_than_50,\n",
    "        is_count_of_observations_less_than_100k ,\n",
    "        is_count_of_observations_less_than_10k ,\n",
    "        y_type ,\n",
    "        is_few_features_important ,\n",
    "        is_any_data_text ,\n",
    "        is_target_categorical ,\n",
    "        is_target_quantity,\n",
    "        is_exploration ,\n",
    "        is_data_labeled ,\n",
    "        is_number_categories_known ,\n",
    "        number_observations,\n",
    "        X,\n",
    "        Y)\n",
    "\n",
    "def get_target_variable_type():\n",
    "    #ask user for type of Y:\n",
    "    y_type_raw = str.lower(input(\"Choose 1: Is Y 'categorical', a 'quantity', or are you just 'exploring'?\\n\"))\n",
    "    y_type = str.lower(''.join([character for character in y_type_raw if \\\n",
    "                      character.isalpha()]))\n",
    "    if \"exploring\" in y_type:\n",
    "        y_type = \"exploring\"\n",
    "    if y_type not in (\"categorical\", \"quantity\", \"exploring\"):\n",
    "        raise Exception(\"answer must be 'categorical','quantity', or 'exploring'\")\n",
    "    return y_type\n",
    "\n",
    "def get_is_few_features_important():\n",
    "    #ask user if only few features are important \n",
    "    is_few_features_important = ask_if_true(\"Should few features be important?:\\n\")\n",
    "    return is_few_features_important\n",
    "\n",
    "def get_is_any_data_text():\n",
    "    #ask user if any of the data is text \n",
    "    ##TODO in the future: check why Naive Beyes is good for text data\n",
    "    ##Then use that information to check for text data yourself if possible\n",
    "    is_any_data_text = ask_if_true(\"Is any of the data text?:\\n\")\n",
    "    return is_any_data_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification: training for Categorical (target) with Labels\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def do_LinearSVC(X_train, Y_train, X_test, Y_test):\n",
    "    model = LinearSVC(random_state=0)\n",
    "    model.fit(X_train,Y_train)\n",
    "    zipped = zip(model.predict(X_test), Y_test)\n",
    "    print(*zipped)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def do_NaiveBayes(X_train, Y_train, X_test, Y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X,Y)\n",
    "    zipped = zip(model.predict(X_test), Y_test)\n",
    "    print(*zipped)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def do_KNeighborsClassifier(X_train, Y_train, X_test, Y_test):\n",
    "    model = KNeighborsClassifier(n_neighbors=(len(X_train)/10+1))\n",
    "    model.fit(X,Y)\n",
    "    zipped = zip(model.predict(X_test), Y_test)\n",
    "    print(*zipped)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn import svm\n",
    "\n",
    "def do_SVC(X_train, Y_train, X_test, Y_test):\n",
    "    model = svm.SVC()\n",
    "    zipped = zip(model.predict(X_test), Y_test)\n",
    "    print(*zipped)\n",
    "    return model    \n",
    "\n",
    "##########################################################################\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def do_SGDClassifier(X_train, Y_train, X_test, Y_test, max_iterations = 1000):\n",
    "    model = SGDClassifier(max_iter=max_iterations, tol=1e-3)\n",
    "    zipped = zip(model.predict(X_test), Y_test)\n",
    "    print(*zipped)\n",
    "    return model   \n",
    "\n",
    "##########################################################################\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "def do_KernelApproximation(X_train, Y_train, X_test, Y_test):\n",
    "    rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "    X_features_train = rbf_feature.fit_transform(X_train)\n",
    "    X_features_test = rbf_feature.fit_transform(X_test)\n",
    "    model = do_SGDClassifier(X_features, Y_train, X_features_test, Y_test, max_iterations = 5)\n",
    "    \n",
    "##########################################################################\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deminsionality reduction\n",
    "\n",
    "def do_Randomized_PCA():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering: training for Categorical (target) without Labels\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def do_KMeans(X_train, Y_train, X_test, Y_test):\n",
    "    model = KMeans(n_clusters=2, random_state=0).fit(X_train)\n",
    "#     zipped = zip(model.predict(X_test), Y_test)\n",
    "#     print(*zipped)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def do_gmm(X_train, Y_train, X_test, Y_test):\n",
    "    model = GaussianMixture(n_components=2, random_state=0).fit(X)\n",
    "#     zipped = zip(model.predict(X_test), Y_test)\n",
    "#     print(*zipped)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def do_SpectralClustering(X_train, Y_train, X_test, Y_test):\n",
    "    model = SpectralClustering(n_clusters=2,\n",
    "            assign_labels=\"discretize\",\n",
    "            random_state=0).fit(X)\n",
    "#     zipped = zip(model.predict(X_test), Y_test)\n",
    "#     print(*zipped)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "#I don't actually understand what is going on for Mini Batch KMeans\n",
    "\n",
    "#     kmeans = MiniBatchKMeans(n_clusters=2,\n",
    "#                              random_state=0,\n",
    "#                              batch_size=6)\n",
    "#     kmeans = kmeans.partial_fit(X[0:6,:])\n",
    "#     kmeans = kmeans.partial_fit(X[6:12,:])\n",
    "#     minibatch kmeans, MeanShift, VBGMM\n",
    "    \n",
    "##########################################################################\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "def do_MeanShift(X_train, y_train, X_test, Y_test):\n",
    "    model = MeanShift()\n",
    "    model.fit(X)\n",
    "#     cluster_centers = model.cluster_centers_\n",
    "#     labels = model.labels_   \n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def do_GaussianMixture(X_train, y_train, X_test, Y_test):\n",
    "    model = GaussianMixture()\n",
    "    model.fit(X)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression: Training for non-categorical quantity (target)\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def do_SGDRegressor(X_train, y_train, X_test, Y_test):   \n",
    "    model = SGDRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def do_Lasso(X_train, y_train, X_test, Y_test):\n",
    "    model = Lasso() \n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def do_ElasticNet(X_train, y_train, X_test, Y_test): \n",
    "    model = ElasticNet()\n",
    "    model.fit(X_train, y_train)\n",
    "#     print(model.coef_)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def do_Ridge(X_train, y_train, X_test, Y_test):\n",
    "    model = Ridge()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def do_linear_SVR(X_train, y_train, X_test, Y_test):\n",
    "    model = SVR(kernel=linear)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_algorithms = [do_LinearSVC, do_NaiveBayes, do_KNeighborsClassifier, do_SVC, do_SGDClassifier, do_KernelApproximation]\n",
    "dimensionality_reduction_algorithms = [do_Randomized_PCA]\n",
    "#replaced VBGMM with GaussianMixture\n",
    "clustering_algorithms = [do_KMeans, do_gmm, do_SpectralClustering, MiniBatchKMeans, do_MeanShift, do_GaussianMixture]\n",
    "regression_algorithms = [do_SGDRegressor, do_Lasso, do_ElasticNet, do_Ridge, do_linear_SVR]\n",
    "all_algorithms = classification_algorithms + dimensionality_reduction_algorithms + clustering_algorithms + regression_algorithms\n",
    "\n",
    "data_labeled = ['do_LinearSVC', \n",
    "'do_NaiveBayes', \n",
    "'do_KNeighborsClassifier', \n",
    "'do_SVC', \n",
    "'do_SGDClassifier', \n",
    "'do_KernelApproximation']\n",
    "\n",
    "number_categories_known = ['do_KMeans', \n",
    "'do_gmm', \n",
    "'do_SpectralClustering', \n",
    "'MiniBatchKMeans']\n",
    "\n",
    "more_than_100k = ['do_SGDClassifier', \n",
    "'do_KernelApproximation', 'do_SGDRegressor']\n",
    "\n",
    "more_than_10k = ['MiniBatchKMeans', \n",
    "'do_MeanShift', \n",
    "'do_VBGMM','do_KernelApproximation'] + more_than_100k\n",
    "\n",
    "predicting_category = ['do_LinearSVC', \n",
    "'do_NaiveBayes', \n",
    "'do_KNeighborsClassifier', \n",
    "'do_SVC', \n",
    "'do_SGDClassifier', \n",
    "'do_KernelApproximation', \n",
    "'do_KMeans', \n",
    "'do_gmm', \n",
    "'do_SpectralClustering', \n",
    "'MiniBatchKMeans', \n",
    "'do_MeanShift', \n",
    "'do_GaussianMixture'] #replaced VBGMM with GaussianMixture\n",
    "\n",
    "predicting_quantity = ['do_SGDRegressor', \n",
    "'do_Lasso', \n",
    "'do_ElasticNet', \n",
    "'do_Ridge', \n",
    "'do_linear_SVR']\n",
    "\n",
    "exploring = ['do_Randomized_PCA']\n",
    "\n",
    "labeled_data = ['do_LinearSVC', \n",
    "'do_NaiveBayes', \n",
    "'do_KNeighborsClassifier', \n",
    "'do_SVC', \n",
    "'do_SGDClassifier', \n",
    "'do_KernelApproximation', 'do_SGDRegressor', \n",
    "'do_Lasso', \n",
    "'do_ElasticNet', \n",
    "'do_Ridge', \n",
    "'do_linear_SVR']\n",
    "\n",
    "number_categories_known = ['do_KMeans', \n",
    "'do_gmm', \n",
    "'do_SpectralClustering', \n",
    "'MiniBatchKMeans']\n",
    "\n",
    "is_there_text_data = ['do_NaiveBayes']\n",
    "\n",
    "few_features_important = ['do_Lasso', \n",
    "'do_ElasticNet']\n",
    "\n",
    "class DataFromUser:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_responses_for_algorithm(algorithm_func = do_LinearSVC):\n",
    "        algorithm = algorithm_func.__name__\n",
    "        default = False\n",
    "        if default == True:\n",
    "            self.is_data_labeled = False\n",
    "            self.is_number_categories_known = False\n",
    "#             self.number_observations = 0\n",
    "            self.is_count_of_observations_more_than_50 = True \n",
    "            self.is_count_of_observations_less_than_100k = False\n",
    "            self.is_count_of_observations_less_than_10k = False\n",
    "            self.y_type = \"categorical\" #np.random.choice([\"categorical\", \"quantity\", \"exploring\"])\n",
    "            self.is_few_features_important = False\n",
    "            self.is_any_data_text = False\n",
    "            (self.is_target_categorical, \n",
    "             self.is_target_quantity, \n",
    "             self.is_exploration) = derive_from_type_of_target_variable(y_type)\n",
    "            \n",
    "        else:\n",
    "            self.is_data_labeled = algorithm in data_labeled\n",
    "            self.is_number_categories_known = algorithm in number_categories_known\n",
    "#             self.number_observations = 0\n",
    "            self.is_count_of_observations_more_than_50 = True \n",
    "            self.is_count_of_observations_less_than_100k = algorithm in more_than_100k\n",
    "            self.is_count_of_observations_less_than_10k = algorithm in more_than_10k\n",
    "#             self.y_type = \"categorical\" #np.random.choice([\"categorical\", \"quantity\", \"exploring\"])\n",
    "            self.is_few_features_important = algorithm in few_features_important\n",
    "            self.is_any_data_text = algorithm in is_there_text_data\n",
    "            self.is_target_categorical = algorithm in predicting_category \n",
    "            self.is_target_quantity = algorithm in predicting_quantity\n",
    "            self.is_exploration = algorithm in exploring\n",
    "          \n",
    "            \n",
    "    def all_user_responses(self):\n",
    "        return (self.is_data_labeled,\n",
    "                self.is_number_categories_known,\n",
    "#                 self.number_observations,\n",
    "                self.is_count_of_observations_more_than_50,\n",
    "                self.is_count_of_observations_less_than_100k,\n",
    "                self.is_count_of_observations_less_than_10k,\n",
    "#                 self.y_type, #np.random.choice([\"categorical\", \"quantity\", \"exploring\"])\n",
    "                self.is_few_features_important,\n",
    "                self.is_any_data_text,\n",
    "                self.is_target_categorical, \n",
    "                self.is_target_quantity, \n",
    "                self.is_exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def condition_categorical_with_labels(is_count_of_observations_less_than_100k,\n",
    "                                      is_any_data_text, \n",
    "                                      X_train = [], Y_train = [], \n",
    "                                      X_test = [], Y_test = [],\n",
    "                                      model = ''):\n",
    "    print(\"This is a Classification Problem \")\n",
    "    print(\"because you are predicting a category and have labeled data\")\n",
    "    if is_count_of_observations_less_than_100k:\n",
    "        print(\"Start with LinearSVC \")\n",
    "        #print(\"because this is a classification problem with more than 100,000 observations\")\n",
    "        print(\"because there are less than 100,000 observations\")\n",
    "        model = do_LinearSVC(X_train, Y_train, X_test, Y_test)\n",
    "        has_LinearSVC_worked = ask_if_true(\"Has LinearSVC worked?\")\n",
    "        if (not has_LinearSVC_worked) and is_any_data_text:\n",
    "            print(\"Use Naive Bayes \")\n",
    "            #print(\"because it is a classification problem with less than 100,000 observations, Linear SVC didn't work, and there is text data\")\n",
    "            print(\"because Linear SVC didn't work and there is text data\")\n",
    "            model = do_NaiveBayes(X_train, Y_train, X_test, Y_test)\n",
    "        elif (not has_LinearSVC_worked) and (not is_any_data_text):\n",
    "            print(\"Use K Neighbors Classifier \")\n",
    "#                    print(\"because it is a classification problem with less than 100,000 observations, Linear SVC didn't work, and there is no text data\")\n",
    "            print(\"because Linear SVC didn't work and there is not any text data\")\n",
    "            model = do_KNeighborsClassifier(X_train, Y_train, X_test, Y_test)\n",
    "            has_KNeighbors_Classifier_worked = ask_if_true(\"Has K Neighbors Classifier worked?\")\n",
    "            if not has_KNeighbors_Classifier_worked:\n",
    "                print(\"Use SVC or Ensemble Classifiers \")\n",
    "                #print(\"because it is a classification problem with less than 100,000 observations, Linear SVC didn't work, there is text data, and KNeighborsClassifier didn't work\")            \n",
    "                print(\"because KNeighborsClassifier didn't work\")\n",
    "    elif not is_count_of_observations_less_than_100k:\n",
    "        print(\"Start with SGD Classifier \")\n",
    "        print(\"because there are at least 100,000 observations\")\n",
    "        model = do_SGDClassifier(X_train, Y_train, X_test, Y_test)\n",
    "        has_SGD_Classifier_worked = ask_if_true(\"Has SGD Classifier worked?\")\n",
    "        if not has_SGD_Classifier_worked:\n",
    "            print(\"Use Kernel Approximation \")\n",
    "            #print(\"because it is a classification problem with more than 100,000 observations, Linear SVC didn't work, and there is text data\")\n",
    "            print(\"because SGD Classifier didn't work\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_categorical_without_labels(is_number_categories_known,\n",
    "                                         is_count_of_observations_less_than_10k,\n",
    "                                         X_train = [], Y_train = [], \n",
    "                                         X_test = [], Y_test = [], \n",
    "                                         model = ''):\n",
    "    print(\"This is a Clustering problem \")\n",
    "    print(\"because you are predicting a category and do not have labeled data\")\n",
    "    if is_number_categories_known and is_count_of_observations_less_than_10k:\n",
    "        print(\"Start with K Means Cluster\")\n",
    "        #print(\"because this is a clustering problem and you have less than 10,000 samples\")\n",
    "        print(\"because the number of categories is known and there are less than 10,000 observations\")\n",
    "        has_KMeans_worked = ask_if_true(\"Has KMeans worked?\")\n",
    "        if not has_KMeans_worked:\n",
    "            print(\"Use GMM or Spectral Clustering \")\n",
    "            print(\"because K Means didn't work\")\n",
    "    elif is_number_categories_known and not is_count_of_observations_less_than_10k:\n",
    "            print(\"Use MiniBatch KMeans \")\n",
    "            print(\"because the number of categories is known and there are at least 10,000 observations\")\n",
    "    elif not is_number_categories_known and not is_count_of_observations_less_than_10k:\n",
    "        print(\"You need more observations or potentially assume (or otherwisse figure out) the number of categories\")\n",
    "    elif not is_number_categories_known and is_count_of_observations_less_than_10k:\n",
    "        print(\"Use MeanShift or VBGMM \")\n",
    "        print(\"because the number of categories is not known and there are less than 10,000 observations\")                \n",
    "    return model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_predicting_quantity(is_count_of_observations_less_than_100k,\n",
    "                                  is_few_features_important, \n",
    "                                  X_train = [], Y_train = [], \n",
    "                                  X_test = [], Y_test = [], \n",
    "                                  model = ''):\n",
    "    print(\"This is a Regression problem \")\n",
    "    print(\"because you are predicting a quantity\")\n",
    "    if not is_count_of_observations_less_than_100k:\n",
    "        print(\"Use SGC Regressor \")\n",
    "        print(\"because there are at least 100,000 observations\")\n",
    "    elif is_count_of_observations_less_than_100k and is_few_features_important:\n",
    "        print(\"Use Lasso Regression or ElasticNet Regression \")\n",
    "        print(\"because there are less than 100,000 observations and only a few features should be important\")\n",
    "    elif is_count_of_observations_less_than_100k and not is_few_features_important:\n",
    "        print(\"Start with Ridge Regression and/or SVR(kernel='linear')\")\n",
    "        print(\"because there are less than 100,000 observations and it is not necessary for only a few features to be important\")\n",
    "        have_Ridge_and_SVRLinear_worked = ask_if_true(\"Have either Ridge Regression or SVR worked?\")\n",
    "        if not have_Ridge_and_SVRLinear_worked:\n",
    "            print(\"Use SVR(kernel='rbf') or EnsembleRegressors \")\n",
    "            print(\"because neither Ridge Regression nor SVR(kernel='linear') have worked\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_exploration(is_count_of_observations_less_than_10k, \n",
    "                          X_train = [], Y_train = [], \n",
    "                          X_test = [], Y_test = [], \n",
    "                          model = ''):\n",
    "    print(\"This is a Dimensionality Reduction problem \")\n",
    "    print(\"because you are exploring rather than predicting a category or quantity\")\n",
    "    print(\"Start with Randomized PCA\")\n",
    "    has_randomized_PCA_worked = ask_if_true(\"Has randomized PCA worked?\")\n",
    "    if not has_randomized_PCA_worked and is_count_of_observations_less_than_10k:\n",
    "        print(\"Use kernel approximation \")\n",
    "        print(\"because Randomized PCA did not work and there are at least 10,000 observations\")\n",
    "    elif not has_randomized_PCA_worked and not is_count_of_observations_less_than_10k:\n",
    "        print(\"Use Isomap or Spectral Embedding \")\n",
    "        print(\"because Randomized PCA did not work and there are at least 10,000 observations\")\n",
    "        has_Isomap_or_SpectralEmbedding_worked = ask_if_true(\"Has either Isomap or Spectral Embedding worked?\")\n",
    "        if not has_Isomap_or_SpectralEmbedding_worked:\n",
    "            print(\"Use LLE \")\n",
    "            print(\"because neither Isomap nor Spectral Embedding have worked\")\n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# is_count_of_observations_more_than_50 = False\n",
    "# is_count_of_observations_less_than_100k = False\n",
    "# is_count_of_observations_less_than_10k = False\n",
    "# y_type = ''\n",
    "# is_few_features_important = False\n",
    "# is_any_data_text = False\n",
    "# is_target_categorical = False\n",
    "# is_target_quantity = False\n",
    "# is_exploration = False\n",
    "# is_data_labeled = False\n",
    "# is_number_categories_known = False\n",
    "# number_observations = 0\n",
    "# X = []\n",
    "# Y = []\n",
    "def main(is_count_of_observations_more_than_50,\n",
    "    is_count_of_observations_less_than_100k ,\n",
    "    is_count_of_observations_less_than_10k ,\n",
    "    y_type ,\n",
    "    is_few_features_important ,\n",
    "    is_any_data_text ,\n",
    "    is_target_categorical ,\n",
    "    is_target_quantity,\n",
    "    is_exploration ,\n",
    "    is_data_labeled ,\n",
    "    is_number_categories_known ,\n",
    "    number_observations,\n",
    "    X,\n",
    "    Y):\n",
    "    # initialize variables\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 0)\n",
    "    \n",
    "    #The Algorithm\n",
    "    if not is_count_of_observations_more_than_50:\n",
    "        print(\"Get more data\")\n",
    "        model = ''\n",
    "    elif is_target_categorical and is_data_labeled:\n",
    "        model = condition_categorical_with_labels(is_count_of_observations_less_than_100k,\n",
    "                                          is_any_data_text, X_train, X_test, Y_train, Y_test)\n",
    "    elif is_target_categorical and not is_data_labeled:\n",
    "        model = condition_categorical_without_labels(is_number_categories_known,\n",
    "                                             is_count_of_observations_less_than_10k,\n",
    "                                             X_train, X_test, Y_train, Y_test)\n",
    "    elif is_target_quantity:\n",
    "        model = condition_predicting_quantity(is_count_of_observations_less_than_100k,\n",
    "                                      is_few_features_important, X_train, X_test, Y_train, Y_test)\n",
    "    elif is_exploration:\n",
    "        model = condition_exploration(is_count_of_observations_less_than_10k, X_train, X_test, Y_train, Y_test)   \n",
    "    return (model, X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFromUser' object has no attribute 'is_data_labeled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0fb962544379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnumber_observations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m Y) = get_data(data_generated=True)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m (model, X_train, Y_train, X_test, Y_test) = main(is_count_of_observations_more_than_50,\n",
      "\u001b[0;32m<ipython-input-19-739594af93f3>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(data_generated, filename)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mis_target_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mis_target_quantity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 is_exploration) = makeDataForAnAlgorithm.all_user_responses()\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;31m#debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#         print(is_count_of_observations_more_than_50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b22fac1a02d1>\u001b[0m in \u001b[0;36mall_user_responses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_user_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         return (self.is_data_labeled,\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_number_categories_known\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m#                 self.number_observations,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFromUser' object has no attribute 'is_data_labeled'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/application_data.csv',\n",
    "           usecols=['SK_ID_CURR',\n",
    "                    'TARGET',\n",
    "                    'FLAG_OWN_CAR',\n",
    "                    'FLAG_OWN_REALTY',\n",
    "                    'AMT_INCOME_TOTAL',\n",
    "                    'AMT_CREDIT', \n",
    "                    'DAYS_EMPLOYED', \n",
    "                    'EXT_SOURCE_2', \n",
    "\n",
    "                    'AMT_GOODS_PRICE',\n",
    "                    'DAYS_EMPLOYED',\n",
    "                    'FLAG_EMP_PHONE',\n",
    "                    'FLAG_WORK_PHONE',\n",
    "                    'FLAG_CONT_MOBILE',\n",
    "                    'FLAG_PHONE',\n",
    "                    'FLAG_EMAIL',\n",
    "                    'YEARS_BUILD_AVG',\n",
    "                    'COMMONAREA_AVG',\n",
    "                    'ELEVATORS_AVG',\n",
    "                    \n",
    "                    'CODE_GENDER',\n",
    "                    'DAYS_BIRTH', 'HOUR_APPR_PROCESS_START', \n",
    "                    'WEEKDAY_APPR_PROCESS_START']) \n",
    "\n",
    "X = df[['SK_ID_CURR',\n",
    "        'FLAG_OWN_CAR',\n",
    "        'FLAG_OWN_REALTY',\n",
    "        'AMT_INCOME_TOTAL',\n",
    "        'AMT_CREDIT', \n",
    "        'DAYS_EMPLOYED', \n",
    "        'EXT_SOURCE_2', \n",
    "\n",
    "        'AMT_GOODS_PRICE',\n",
    "        'DAYS_EMPLOYED',\n",
    "        'FLAG_EMP_PHONE',\n",
    "        'FLAG_WORK_PHONE',\n",
    "        'FLAG_CONT_MOBILE',\n",
    "        'FLAG_PHONE',\n",
    "        'FLAG_EMAIL',\n",
    "        'YEARS_BUILD_AVG',\n",
    "        'COMMONAREA_AVG',\n",
    "        'ELEVATORS_AVG',\n",
    "\n",
    "        'CODE_GENDER',\n",
    "        'DAYS_BIRTH', 'HOUR_APPR_PROCESS_START', \n",
    "        'WEEKDAY_APPR_PROCESS_START']]\n",
    "\n",
    "Y = df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commented out code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #get data\n",
    "    (is_count_of_observations_more_than_50,\n",
    "    is_count_of_observations_less_than_100k ,\n",
    "    is_count_of_observations_less_than_10k ,\n",
    "    y_type ,\n",
    "    is_few_features_important ,\n",
    "    is_any_data_text ,\n",
    "    is_target_categorical ,\n",
    "    is_target_quantity,\n",
    "    is_exploration ,\n",
    "    is_data_labeled ,\n",
    "    is_number_categories_known ,\n",
    "    number_observations,\n",
    "    X,\n",
    "    Y) = get_data(data_generated=True)\n",
    "    \n",
    "(model, X_train, Y_train, X_test, Y_test) = main(is_count_of_observations_more_than_50,\n",
    "    is_count_of_observations_less_than_100k ,\n",
    "    is_count_of_observations_less_than_10k ,\n",
    "    y_type ,\n",
    "    is_few_features_important ,\n",
    "    is_any_data_text ,\n",
    "    is_target_categorical ,\n",
    "    is_target_quantity,\n",
    "    is_exploration ,\n",
    "    is_data_labeled ,\n",
    "    is_number_categories_known ,\n",
    "    number_observations,\n",
    "    X,\n",
    "    Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #debugging\n",
    "#     print(is_count_of_observations_more_than_50)\n",
    "#     print(is_count_of_observations_less_than_100k )\n",
    "#     print(is_count_of_observations_less_than_10k )\n",
    "#     print(y_type )\n",
    "#     print(is_few_features_important )\n",
    "#     print(is_any_data_text )\n",
    "#     print(is_target_categorical )\n",
    "#     print(is_target_quantity)\n",
    "#     print(is_exploration )\n",
    "#     print(is_data_labeled )\n",
    "#     print(is_number_categories_known )\n",
    "#     print(number_observations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ''\n",
    "# if __name__ == \"__main__\":\n",
    "#     model = main()\n",
    "\n",
    "#     for _ in range(10):\n",
    "#         main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # is_count_of_observations_more_than_50\n",
    "# # is_count_of_observations_less_than_100k\n",
    "# # is_count_of_observations_less_than_10k\n",
    "# # y_type\n",
    "# # is_few_features_important\n",
    "# # is_any_data_text\n",
    "# # is_target_categorical\n",
    "# # is_target_quantity\n",
    "# # is_exploration\n",
    "# # is_data_labeled  \n",
    "# # is_number_categories_known\n",
    "# if not is_count_of_observations_more_than_50:\n",
    "#     print(\"Get more data\")\n",
    "# elif is_target_categorical:\n",
    "#     if is_data_labeled:\n",
    "#         print(\"This is a Classification Problem \")\n",
    "#         print(\"because you are predicting a category and have labeled data\")\n",
    "#         if is_count_of_observations_less_than_100k:\n",
    "#             print(\"Use LinearSVC \")\n",
    "#             #print(\"because this is a classification problem with more than 100,000 observations\")\n",
    "#             print(\"because there are less than 100,000 observations\")\n",
    "#             has_LinearSVC_worked = ask_if_true(\"Has LinearSVC worked?\")\n",
    "#             if (not has_LinearSVC_worked) and is_any_data_text:\n",
    "#                 print(\"Use Niave Bayes \")\n",
    "#                 #print(\"because it is a classification problem with less than 100,000 observations, Linear SVC didn't work, and there is text data\")\n",
    "#                 print(\"because Linear SVC didn't work and there is text data\")\n",
    "#             elif (not has_LinearSVC_worked) and (not is_any_data_text):\n",
    "#                 print(\"Use K Neighbors Classifier \")\n",
    "# #                    print(\"because it is a classification problem with less than 100,000 observations, Linear SVC didn't work, and there is no text data\")\n",
    "#                 print(\"because Linear SVC didn't work and there is not any text data\")\n",
    "#                 has_KNeighbors_Classifier_worked = ask_if_true(\"Has K Neighbors Classifier worked?\")\n",
    "#                 if not has_KNeighbors_Classifier_worked:\n",
    "#                     print(\"Use SVC or Ensemble Classifiers \")\n",
    "#                     #print(\"because it is a classification problem with less than 100,000 observations, Linear SVC didn't work, there is text data, and KNeighborsClassifier didn't work\")            \n",
    "#                     print(\"because KNeighborsClassifier didn't work\")\n",
    "#         elif not is_count_of_observations_less_than_100k:\n",
    "#             print(\"Use SGD Classifier \")\n",
    "#             print(\"because there are at least 100,000 observations\")\n",
    "#             has_SGD_Classifier_worked = ask_if_true(\"Has SGD Classifier worked?\")\n",
    "#             if not has_SGD_Classifier_worked:\n",
    "#                 print(\"Use Kernel Approximation \")\n",
    "#                 #print(\"because it is a classification problem with more than 100,000 observations, Linear SVC didn't work, and there is text data\")\n",
    "#                 print(\"because SGD Classifier didn't work\")\n",
    "#     elif not is_data_labeled:\n",
    "#         print(\"This is a Clustering problem \")\n",
    "#         print(\"because you are predicting a category and do not have labeled data\")\n",
    "#         if is_number_categories_known and is_count_of_observations_less_than_10k:\n",
    "#             print(\"Use K Means \")\n",
    "#             #print(\"because this is a clustering problem and you have less than 10,000 samples\")\n",
    "#             print(\"because the number of categories is known and there are less than 10,000 observations\")\n",
    "#             has_KMeans_worked = ask_if_true(\"Has KMeans worked?\")\n",
    "#             if not has_KMeans_worked:\n",
    "#                 print(\"Use GMM or Spectral Clustering \")\n",
    "#                 print(\"because K Means didn't work\")\n",
    "#         elif is_number_categories_known and not is_count_of_observations_less_than_10k:\n",
    "#                 print(\"Use MiniBatch KMeans \")\n",
    "#                 print(\"because the number of categories is known and there are at least 10,000 observations\")\n",
    "#         elif not is_number_categories_known and not is_count_of_observations_less_than_10k:\n",
    "#             print(\"You need more observations or potentially assume (or otherwisse figure out) the number of categories\")\n",
    "#         elif not is_number_categories_known and is_count_of_observations_less_than_10k:\n",
    "#             print(\"Use MeanShift or VBGMM \")\n",
    "#             print(\"because the number of categories is not known and there are less than 10,000 observations\")\n",
    "# elif is_target_quantity:\n",
    "#     print(\"This is a Regression problem \")\n",
    "#     print(\"because you are predicting a quantity\")\n",
    "#     if not is_count_of_observations_less_than_100k:\n",
    "#         print(\"Use SGC Regressor \")\n",
    "#         print(\"because there are at least 100,000 observations\")\n",
    "#     elif is_count_of_observations_less_than_100k and is_few_features_important:\n",
    "#         print(\"Use Lasso Regression or ElasticNet Regression \")\n",
    "#         print(\"because there are less than 100,000 observations and only a few features should be important\")\n",
    "#     elif is_count_of_observations_less_than_100k and not is_few_features_important:\n",
    "#         print(\"Use Ridge Regression or SVR(kernel='linear')\")\n",
    "#         print(\"because there are less than 100,000 observations and it is not necessary for only a few features to be important\")\n",
    "#         have_Ridge_and_SVRLinear_worked = ask_if_true(\"Have either Ridge Regression or SVR worked?\")\n",
    "#         if not have_Ridge_and_SVRLinear_worked:\n",
    "#             print(\"Use SVR(kernel='rbf') or EnsembleRegressors \")\n",
    "#             print(\"because neither Ridge Regression nor SVR(kernel='linear') have worked\")\n",
    "# elif is_exploration:\n",
    "#     print(\"This is a Dimensionality Reduction problem\")\n",
    "#     print(\"Start with Randomized PCA\")\n",
    "#     has_randomized_PCA_worked = ask_if_true(\"Has randomized PCA worked?\")\n",
    "#     if not has_randomized_PCA_worked and is_count_of_observations_less_than_10k:\n",
    "#         print(\"Use kernel approximation \")\n",
    "#         print(\"because Randomized PCA did not work and there are at least 10,000 observations\")\n",
    "#     elif not has_randomized_PCA_worked and not is_count_of_observations_less_than_10k:\n",
    "#         print(\"Use Isomap or Spectral Embedding \")\n",
    "#         print(\"because Randomized PCA did not work and there are at least 10,000 observations\")\n",
    "#         has_Isomap_or_SpectralEmbedding_worked = ask_if_true(\"Has either Isomap or Spectral Embedding worked?\")\n",
    "#         if not has_Isomap_or_SpectralEmbedding_worked:\n",
    "#             print(\"Use LLE \")\n",
    "#             print(\"because neither Isomap nor Spectral Embedding have worked\")\n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
